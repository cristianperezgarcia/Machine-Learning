# -*- coding: utf-8 -*-
"""Gestión datos faltantes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Omrq4oxJ10e3Ki_GHlo8AtI1WRNUzn8g

# Métodos para procesar valores faltantes
En los siguientes bloques se prueban diferentes métodos para manejar los valores faltantes:

- Eliminación de filas con valores faltantes. (poco recomendado)
- Sustitución con la media.( o la mediana porque es menos robusta)
- Interpolación con valores cercanos. (en series temporales, por lógica)
- Imputación mediante otros algoritmos.

En cada método, se realiza lo siguiente:
- Se aplica la técnica de imputación correspondiente a los datos de entrenamiento, y test cuando corresponda.
- Se evalúa el rendimiento de un modelo de regresión lineal con los datos modificados.

El cuadernillo demuestra una aplicación práctica de estos métodos en un conjunto de datos y proporciona una comparación  de su rendimiento.

 Este tipo de análisis es crucial en el preprocesamiento de datos para el aprendizaje automático y la modelización estadística, donde la calidad y la integridad de los datos pueden influir significativamente en los resultados del modelo.
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Definimos la URL del conjunto de datos
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"

# Especificamos los nombres de las columnas
column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin', 'Car Name']

# Cargamos los datos en un DataFrame de pandas
data = pd.read_csv(url, delim_whitespace=True, names=column_names, na_values='?')

# Eliminamos las columna 'Car Name' y 'Origin' ya que no es relevante para nuestro análisis
data = data.drop('Car Name', axis=1)

data = data.drop('Origin', axis=1)

# Mostramos las primeras filas del DataFrame
data

#Colocamos la variable objetivo al final
data = data[['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'MPG']]

#Establecemos las variables predictoras:
predictors = ['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year']

"""## Dividimos en Entrenamiento y Test

Lo hacemos de forma manual, sin librería, pues no queremos separar por ahora las variables predictoras y la variable objetivo, y las librerías no nos permiten trabajr de esa manera.
"""

# Establecemos una semilla para la reproducibilidad
np.random.seed(0)

# Mezclamos los datos de forma aleatoria
shuffled_indices = np.random.permutation(len(data))

# Calculamos el tamaño del conjunto de prueba (20% de los datos)
test_set_size = int(len(data) * 0.2)

# Creamos los índices para los conjuntos de prueba y entrenamiento
test_indices = shuffled_indices[:test_set_size]
train_indices = shuffled_indices[test_set_size:]
test_indices

# Creamos los conjuntos de prueba y entrenamiento sin separación entre variables predictoras y objetivo
train_set = data.iloc[train_indices]#iloc para coger numeros
test_set = data.iloc[test_indices]

# Entrenamos un modelo de regresión lineal
# Separamos en train y test
X_train= train_set[predictors]
y_train=train_set['MPG']


#utilizamos una secuencia 'try' pues esperamos que nos devuelva ub error
try:
  model  = LinearRegression()
  model.fit(X_train, y_train)
except Exception as e:
  print(f"Error al entrenar el modelo: {e}")
  #Da error porque no hemos eliminados los nan ya que el otro dia lo que hicimos es eliminar las filas dónde había missings

"""El modelo no funciona si existen modelos faltantes.

## Gestión de Nans

En primer lugar, vamos a introducir más datos faltantes para un toque más realista.
"""

def insert_random_nans(df, percentage, seed=42):
    """
    Inserta valores NaN de manera aleatoria en un DataFrame.

    Parámetros:
    df (pandas.DataFrame): DataFrame original.
    percentage (float): Porcentaje de valores a convertir en NaN.
    seed (int): Semilla para la generación de números aleatorios (por defecto 42).

    Devuelve:
    pandas.DataFrame: Nuevo DataFrame con NaNs insertados.
    """
    # Crear una copia del DataFrame para evitar modificar el original
    df_with_nans = df.copy()

    # Calcular el número total de elementos en el DataFrame
    total_elements = df_with_nans.size

    # Calcular el número exacto de NaNs a insertar basándose en el porcentaje dado
    nans_to_insert = int(total_elements * percentage)

    # Establecer la semilla para asegurar la reproducibilidad en la generación de números aleatorios
    np.random.seed(seed)

    # Iterar para insertar la cantidad calculada de NaNs
    for _ in range(nans_to_insert):
        # Seleccionar una fila al azar dentro del rango del DataFrame
        random_row =np.random.randint(0,len(df_with_nans))

        # Seleccionar una columna al azar dentro del rango de columnas del DataFrame
        random_column = np.random.randint(0,df_with_nans.shape[1])

        # Asignar el valor NaN en la posición aleatoria determinada por fila y columna
        df_with_nans.iat[random_row, random_column] = np.nan

    # Devolver el nuevo DataFrame con NaNs insertados
    return df_with_nans

# Añadimos NaNs en el conjunto de entrenamiento en porcentaje del 10% (En las variables predictoras y en la variable objetivo)
train_set_nans = insert_random_nans(df = train_set,percentage = 0.1)

# Analizamos el contenido con .info()
train_set_nans.info()

"""En el conjunto de test sólo introducimos NaNs en las variables predictoras.

 No tiene sentido la existencia de valores faltantes en la variable objetivo del conjunto de test pues este conjunto trata de simular los datos de producción y en la realidad nunca vamos a disponer de la variable objetivo, pues es la que deseamos predecir.
"""

# Separamos en train y test
X_test = test_set[predictors]
y_test = test_set['MPG']

# Añadimos NaNs en el conjunto de test (Sólo en las variables predictoras)
X_test_nans  = insert_random_nans(X_test,0.1)

# Añadimos la variable objetivo correspondiente al conjunto de test, con lo que tendremos el conjunto completo
X_test_nans['MPG'] = y_test
test_set_nans = X_test_nans

test_set_nans.info()

"""Comprobamos que la variable objetivo 'MPG' contiene todos los valores.

A modo de resumen, para el experimento hemos introducido NaNs en el conjunto de entrenamiento completo y en las variables predictoras del conjunto de test.

## Eliminamos filas con valores faltantes

El primer método será "cortar por lo sano" eliminando observaciones con valores faltantes. (No muy recomendable)
"""

# Eliminamos las filas del set de entrenamiento con valores faltantes
train_set_removing_nans = train_set_nans.dropna()

# Separar en características y variable objetivo
X_train = train_set_removing_nans[predictors]
y_train = train_set_removing_nans['MPG']

# Entrenamos un modelo de regresión lineal
model = LinearRegression()
model.fit(X_train, y_train)

# Eliminamos las filas del conjunto de test con valores faltantes
test_set_removing_nans = test_set_nans.dropna()

# Evaluamos sobre el conjunto de test completo
X_test = test_set_removing_nans[predictors]
y_test = test_set_removing_nans['MPG']

# Calcular el MSE con los datos de prueba
y_pred= model.predict(X_test)
mse_removing_nans= mean_squared_error(y_test, y_pred)
print(f"MSE después de eliminar filas con NaNs: %.2f " % mse_removing_nans)

"""## Sustituimos los valores faltantes con la media

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna
"""

# Sustituir NaNs con la media de cada columna
train_set_filled_w_mean = train_set_nans.fillna(train_set_nans.mean())
train_set_filled_w_mean.info()
# Esta línea crea un nuevo dataframe, train_set_filled_w_mean, que es una copia de train_set_nans
# donde todos los valores NaN han sido reemplazados por la media de sus respectivas columnas.

# Separar en características y variable objetivo
X_train = train_set_filled_w_mean[predictors]
y_train = train_set_filled_w_mean['MPG']

# Entrenamos un modelo de regresión lineal
model = LinearRegression()
model.fit(X_train, y_train)

"""Para evaluar el modelo en el conjunto de test tendremos dos opciones:



*   Eliminamos las filas con valores faltantes: En este caso es estamos evaluando el modelo en un conjunto de datos de tamaño más pequeño.

*   Sustituimos los valores faltantes con la media: En este caso disponemos de más datos, pero podemos perder algo de fiabilidad en los mismos por las sustituciones.

En un caso real podemos encontrarnos una situación en la que sólo tenemos una observación con datos faltantes con la cual tenemos que hacer una predicción, en cuyo caso sólo nos quedaría buscar algún método de sustitución, lo que corresponde al segundo caso.

Sólo si nos pudiéramos permitir 'dejar' de hacer predicciones para ciertas observaciones, tendría sentido la eliminación de filas en el conjunto de datos, llamémosle, de 'producción'. Aunque no es un caso muy realista, realizaremos el cálculo a modo de demostración.

"""

# Evaluamos sobre el conjunto de test completo
X_test = test_set_removing_nans[predictors]
y_test = test_set_removing_nans['MPG']

# Calcular el MSE con los datos de test
y_pred= model.predict(X_test)
mse_w_mean= mean_squared_error(y_test, y_pred)
print(f"MSE después de rellenar NaNs con la media: %.2f " % mse_w_mean)

"""Al eliminar las filas del conjunto de test, estamos evaluando el modelos con un conjunto de test más pequeño. No tiene que dar necesariamente un resultado peor, pero, en cualquier caso, el resultado será menos fiable pues se evalúa sobre una cantidad de datos menor."""

# Rellenamos el conjunto de test con la media (en y_test no hay faltantes)
test_set_filled_w_mean = test_set_nans.fillna(test_set_nans.mean())

# Evaluamos sobre el conjunto de test completo
X_test = test_set_filled_w_mean[predictors]
y_test = test_set_filled_w_mean['MPG']

# Calcular el MSE con los datos de prueba
y_pred= model.predict(X_test)
mse_w_mean_2= mean_squared_error(y_test, y_pred)
print(f"MSE después de rellenar NaNs con la media también en el conjunto de test: %.2f " % mse_w_mean_2)

"""En este caso, tenemos más filas para evaluar al modelo. Por ello, este resultado no es comparable con el método anterior de eliminar las filas. Si acaso, el resultado es más fiable, y responde a un caso más realista.

## Interpolación de Datos

La interpolación puede tener más sentido frente a la imputación por la media cuando los datos tienen algún ordenamiento lógico, como es el caso de las series temporales.

En este caso nuestros datos no parecen tener ese orden, pero practiquemos en todo caso la interpolación.

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html
"""

# Sustituir NaNs con la media de cada columna
train_set_interpolated = train_set_nans.interpolate(method = 'linear', limit_direction = 'both')

# Separamos en características y variable objetivo
X_train = train_set_interpolated[predictors]
y_train = train_set_interpolated['MPG']

# Entrenamos un modelo de regresión lineal
model = LinearRegression()
model.fit(X_train,y_train )

# Rellenamos el conjunto de test mediante interpolación (en y_test no hay faltantes)
test_set_interpolated = test_set_nans.interpolate(method = 'linear', limit_direction = 'both')

# Evaluamos sobre el conjunto de test completo
X_test = test_set_interpolated[predictors]
y_test = test_set_interpolated['MPG']

# Calcular el MSE con los datos de prueba
y_pred= model.predict(X_test)
mse= mean_squared_error(y_test, y_pred)
print(f"MSE después de rellenar NaNs mediante interpolación también en el conjunto de test: %.2f " % mse) #.2f es para los decimales

"""El resultado es coherente con nuestra estructura de los datos, que no tienen ningún ordenamiento lógico, por lo que la interpolación tiene menos sentido. Así, vemos que esta técnica es menos efectiva en este caso que la sustitución por la media.

## Imputación basada en primeros vecinos

https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html
"""

from sklearn.impute import KNNImputer

# Imputación KNN
imputer = KNNImputer(n_neighbors=5)
train_set_imputed_knn = imputer.fit_transform(train_set_nans)

# En este caso obtenemos un array y no un dataframe
train_set_imputed_knn

# Convertimos el array resultante en un DataFrame
train_set_imputed_knn = pd.DataFrame(train_set_imputed_knn,columns = train_set_nans.columns, index = train_set_nans.index)
train_set_imputed_knn

# Separar en características y variable objetivo
X_train = train_set_imputed_knn [predictors]
y_train = train_set_imputed_knn ['MPG']

# Entrenamos un modelo de regresión lineal
model = LinearRegression()
model.fit(X_train, y_train)

# Visualizamos el conjunto de test
test_set_nans

# Rellenamos el conjunto de test mediante imputación KNN cpn k=5 (en y_test no hay faltantes)
imputer_target = KNNImputer(n_neighbors=5)
test_set_imputed_knn = imputer_target.fit_transform(test_set_nans)

# Convertimos el array resultante en un DataFrame
test_set_imputed_knn = pd.DataFrame(test_set_imputed_knn,columns = test_set_nans.columns , index =test_set_nans.index)

# Ahora 'test_set_imputed_knn' es un DataFrame con los valores imputados
test_set_imputed_knn

# Llevamos a cabo la evaluación
X_test = test_set_imputed_knn[predictors]
y_test = test_set_imputed_knn['MPG']

# Calcular el MSE con los datos de prueba
y_pred= model.predict(X_test)
mse= mean_squared_error(y_test, y_pred)
print(f"MSE después de rellenar NaNs mediante imputación KNN: %.2f " % mse)